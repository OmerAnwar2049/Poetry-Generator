{"cells":[{"cell_type":"markdown","metadata":{"id":"czLFsxeqJTdM"},"source":["### Loading the corpus and tokenizing words"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33585,"status":"ok","timestamp":1618731984038,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"ifz88TXRrZMd","outputId":"3b7122a9-2ad0-48ea-d737-4095a83cd0c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"EqRM0kg4TLQT"},"source":["Reading poetry for the corpus and adding start and end tags. The tokenized words are stored in the list total with start and end tags.\n","\n","\n","*   Creating a list for start words in list start_words\n","\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":914,"status":"ok","timestamp":1618733105411,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"RQtbieXUrbPR"},"outputs":[],"source":["import copy\n","f = open('/content/drive/My Drive/NLP3_i18-0562/corpus.txt', 'r')\n","\n","total = []   #Global list of tokenized words\n","start_words = []  # Global list of start words\n","\n","\n","Lines = f.readlines()\n","\n","count = 0\n","\n","temp = ''\n","\n","for j in Lines:\n","\n","  if len(j)<=3:\n","    continue\n","\n","  words = j.split(' ')\n","  clean = []\n","\n","  # Removing the \\n from the last word\n","  for i in words:\n","    clean.append(i.strip())\n","\n","  # Adding start words to the start words list,make sure that it is not repeated\n","  if clean[0] not in start_words:\n","    start_words.append(clean[0])\n","\n","\n","  #  Adding the start and end tags\n","  clean.insert(0,'<s>')\n","  clean.append('</s>')\n","\n","  # print(clean)\n","  \n","  for i in clean:\n","    total.append(i) \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6ZWnhEjj9-Aa"},"source":["### Storing Rhyme Words"]},{"cell_type":"markdown","metadata":{"id":"J-4SvY6ovhjO"},"source":["Making a rhyming dictionary"]},{"cell_type":"markdown","metadata":{"id":"cW2c_kcOJR8g"},"source":["1. The makePairs() function takes in the list of tokenized words from corpus and return a list of pairs.For rhyming I will rhyme every two verses so the first step is to return a list of pair between every two consecutive verses.\n","\n","2. The pairs returned from the makePairs() functions is sent to the makeRhymes() function. This function basically creates a dictionary where the key is an ending word and the value of that key contains a list of words that can be rhymed with that word.          Example  'نہیں': ['چلے', 'گیا', 'قضا']. Here the key is 'نہیں' and the list contains the words that can be rhymed in the next consecutive verse. In our generation function the rhyme word will be chosen randomly.\n","\n","3. The fillEndList() function simply makes a list of end words filled with keys from the rhyme dictionary. A word will be chosen from this list for even verses in a stanza. For odd verses a word will be chosen randomly from the list of the chosen key. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":846,"status":"ok","timestamp":1618732957947,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"b6PMbOJp24t4","outputId":"c6123aef-e77c-4d64-cd57-19f18a76ec1b"},"outputs":[],"source":["\n","def makePairs(t_list):\n","  pairs = []\n","  count = 1 \n","  for i in range(len(t_list)):\n","    if t_list[i]== '</s>':\n","      if count %2 == 1:\n","        temp1 = copy.deepcopy(t_list[i-1])\n","        count+=1\n","        # print(\"temp1->\",temp1)\n","      elif count %2 == 0:\n","        temp2 = copy.deepcopy(t_list[i-1])\n","        # print(\"temp2->\",temp2)\n","        if (temp1,temp2) not in pairs:\n","          pairs.append(tuple((temp1, temp2)))\n","        count+=1\n","  return pairs\n","\n","pair = makePairs(total)\n","pair\n","      \n","def makeRhymes(pairs):\n","  rhymes = {}\n","  \n","  for i in pairs:\n","    temp = []\n","    if i[0] in rhymes:\n","      continue\n","    word = i[0]\n","\n","    for j in pairs:     \n","      if j[0] == word:\n","        if j[1] not in temp:\n","          temp.append(j[1])  \n","    rhymes[i[0]] = temp\n","  return rhymes\n","\n","\n","\n","# Storing all the keys in the end list function\n","def fillEndList(rhymes):\n","  e_list  = []\n","  for i in rhymes:\n","    e_list.append(i)\n","\n","  return e_list\n","\n","\n","rhymes = makeRhymes(pair)\n","\n","\n","end_words = fillEndList(rhymes)  # Global list of end words,\n","\n","end_words\n"]},{"cell_type":"markdown","metadata":{"id":"BYujvfHy580G"},"source":["### Unigram Model (with rhyming)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1151,"status":"ok","timestamp":1618732960520,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"Ie62ad4nEjjs"},"outputs":[],"source":["import spacy\n","import nltk\n","import random\n","import operator\n","from collections import defaultdict\n","from nltk.probability import ConditionalFreqDist\n","from nltk.util import ngrams\n","from collections import Counter\n","unlp = spacy.blank('ur')"]},{"cell_type":"markdown","metadata":{"id":"x7c3xAKIbqXm"},"source":["Helper function which recives a list of verses and prints them in stanza formation."]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1148,"status":"ok","timestamp":1618732960522,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"uoRkeMv76Pb6"},"outputs":[],"source":["def printVerses(v):\n","\n","  c = 0  \n","  for j in v:\n","    c+=1\n","    for k in range(len(j)):\n","      print(j[k],end = \" \")\n","\n","    print() # end of each verse\n","\n","    if(c %4==0):\n","      print() # end of each stanza"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":1144,"status":"ok","timestamp":1618732960524,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"CsNQuMyHxQRi"},"outputs":[],"source":["def countSingle(word,total):\n","  count = 0\n","  for i in total:\n","    if i == word:\n","      count+=1\n","  return count\n","\n","def countDouble(word1,word2,total):\n","  count = 0\n","  for i in range(len(total)-1):\n","    if total[i] == word1 and total[i+1] == word2:\n","      count+=1\n","  return count\n","\n","def countTriple(word1,word2,word3,total):\n","  count = 0\n","  for i in range(len(total)-2):\n","    if total[i] == word1 and total[i+1] == word2 and total[i+2] == word3:\n","      count+=1\n","  return count"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":1139,"status":"ok","timestamp":1618732960526,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"s86D-Kkl6GvM"},"outputs":[],"source":["def Unigram_Probabilities(total):\n","\n","  u_dict = {}\n","  \n","  temp = []\n","\n","  for i in total:\n","    if i in u_dict:\n","      continue\n","    count =  float(countSingle(i,total)/len(total))\n","    u_dict[i] = count\n","\n","  sorted_dict = sorted(u_dict.items(), key=operator.itemgetter(1))\n","\n","  # REMOVING START AND END TAGS\n","  del sorted_dict[-1]\n","  del sorted_dict[-1]\n","\n","  return sorted_dict\n","  \n","  \n"]},{"cell_type":"markdown","metadata":{"id":"xLmTALHNzGOc"},"source":["Unigram poetry generator function which which generates poetry given tokenized list of words,start words,end words and rhyming list. No predictor function is required since no history required for each word.\n","\n","Logic:\n","1. As seen above after sorting the dictionanry it is natural that the words witht the highest probabilty are going to be coneecting words such as سے ,کیا ,تو etc. These connecting words will be place at the end of the sorted list.\n","\n","2. Similarly words with less probabilty but high value in poetry such as انقلاب' پیمانہ will have low probabilty and will be present in the beginnig of the sorted dictionary.\n","\n","3. Thus for poetry with unigrams (no history) is to start with a word from the list of start words,then choose a coonecting word from the second half of the list followed by a high meaning word from the first half of the list and repeating this procedure until the end of the verse.\n","\n","4. In this way meaning wise the verse will most likely be gibberish but its poosible to maintain some synctactic validity of each verse.\n","\n","\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4500,"status":"ok","timestamp":1618732963893,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"aeSW4UB6zFPS","outputId":"1422adeb-bd91-4e21-c356-3ea26cb5a169"},"outputs":[{"name":"stdout","output_type":"stream","text":["     UNIGRAM MODEL POETRY\n","\n","دیدہ دلستانی تازِ سوزن ہنِ کلام رودادِ گریباں لو‘ تھما \n","بقدرِ تعمیر تا‘ بیٹهے خمیازۂ خلش آنسو‘ ہے؟ \n","آتش لب سفینہ دروازہ رہیو جایا کے؟ چیز تعلیم \n","سُراغِ ہوسِ بھید جولاں جُز آپکو کامل تنہائی بلبلِ تک \n","\n","مژدۂ غم پیراہن اس صرفِ آشیاں دبستاں دلستاں سکتا \n","خانمانِ سرگشہٴ نِدا قد پھرا آساں‘ زبانوں اٹھتا ہوا \n","انِ ملک ک طلبگارِ کشمیر پرواز سویداۓ ہوں! \n","فلکِ چارہ نشینِ دنداں سودائے معاملہ پرفشاں ویرانی \n","\n","ہنوز قضا یاسِ نا امیدوار‘ بعد پارہ دی پر \n","کمالِ پروانہ شاہنشاہ دعا خوبرویوں تک شکائتیں \n","نگاہ لے خصم بازیِ نمط کو! خالِ ہوں! \n","حق جذبہٴ ہا‘ ز جن ہمیں فروغ ویرانی \n","\n"]}],"source":["def Unigram_Poetry(t_words,s_words,e_words,r):\n","\n","  print(\"     UNIGRAM MODEL POETRY\\n\")\n","  \n","  u_prob  = Unigram_Probabilities(total)\n","\n","  verses = []\n","  \n","  e_word = \"\"\n","\n","  for i in range(3):\n","\n","    for j in range(4):\n","\n","      temp = []  # List for storing all the words in this verse and will be appended to the list of lists (verses)\n","\n","      # LENGTH OF VERSE\n","      length = random.randint(7,10)  \n","        \n","      #CHOOSING A START WORD AT RANDOM\n","      index =  random.randint(0,len(s_words)-1)\n","      start_word = s_words[index]\n","      \n","      temp.append(start_word)\n","\n","      for k in range(length-2):\n","\n","        # CHOOSE CONNECTING WORD\n","        if k%2 ==0:\n","          back = random.randint(1,int(len(u_prob)/2))\n","          temp.append(u_prob[-back][0])\n","\n","        # CHOOSE HIGH MEANING WORD\n","        if k%2 ==1:\n","          front = random.randint(0,int(len(u_prob)/2))\n","          temp.append(u_prob[front][0])        \n","\n","                # R H Y M I N G #\n","      # Choosing last word from list of end words (for even verses)\n","      if j%2 == 0:\n","        index2 =  random.randint(0,len(e_words)-1)\n","        e_word = e_words[index2]\n","        temp.append(e_words[index2])\n","\n","      # Choosing rhyme word for rhyming with previous verse (for odd verses only)  \n","      elif j%2 == 1:\n","        rhyme_choice = r[e_word]\n","        choice_index = random.randint(0,len(rhyme_choice)-1)\n","        temp.append(rhyme_choice[choice_index])\n","      \n","      verses.append(temp)  # Appending the current entire verse to verses\n","\n","\n","  printVerses(verses)\n","\n","\n","\n","Unigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"FOoXq--POObz"},"source":["###Simple Bigram Model  (with rhyming)"]},{"cell_type":"markdown","metadata":{"id":"PpViSTcP0w_3"},"source":["Bigram Probability Function\n","\n","The first function is the most improtant function. This function calculates all  the bigram probabilitoes in a 2 Dimemesinal Dictionary.\n","\n","1. Each key in the first dictionary is basically the first word.\n","2. Given key of first word the second dictionary is a list of words that can appear after the first word.Thei value is the probability of the second word appearing after the first word.\n","3. This function then return the 2D list which is used further by the predictor function of different model. \n","\n","EXAMPLE:  'آؤ': {'کریں': 0.5, 'کہ': 0.5}   is one of the entries in this dictionary.\n","1. Here 'آؤ' is the key of the first dictionary.\n","2. The value it holds is the second dictionary  {'کریں': 0.5, 'کہ': 0.5}.\n","3. One of the keys in the second dictionay is کریں and the value is 0.5.\n","4. This shows that the conditional probability of کریں appearing after آؤ is 0.5."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7801,"status":"ok","timestamp":1618732010008,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"do_MFDAXx_4x","outputId":"f4460a72-d7d7-40c1-dd95-dbdd08b7c645"},"outputs":[],"source":["\n","def Bigram_Probabilty(total):\n","\n","  mainDict = defaultdict(list)  # This dictionary holds a list of dictionaries\n","\n","  previous_word = \"\"\n","  for i in total:\n","    if previous_word != \"\":\n","      mainDict[previous_word].append(i)\n","    previous_word = i\n","\n","  for key in mainDict.keys():\n","\n","    count = countSingle(key,total)\n","    # print(key,\"->\",count)\n","    next_words = mainDict[key]  # Getting the whole list of words after the key word\n","    unique_words = set(next_words)  # Remaove duplicates\n","    probabilities_key = {}\n","\n","     # Now we will iterate over the list of words after the key word,and store probabilty with each word\n","    for u in unique_words:\n","      # print(key,\" \",u,\"->\",countDouble(key,u,total))\n","      count2 = countDouble(key,u,total)\n","      probabilities_key[u] = copy.deepcopy(count2/count)\n","\n","    mainDict[key] = probabilities_key\n","\n","  return mainDict\n","    \n","\n","probs = copy.deepcopy(Bigram_Probabilty(total))\n","probs\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fiuINvZBRGME"},"source":["The Bigram predictor Funtion is the second part of the bigram poetry generation that given all the probabilities and the first word how do we predict the next word.\n","\n","Logic:\n","1. The first thing this function does is go to the value of the first dictionary given the first word.\n","2. As explained above the value of the fisrt dictionay key is another dictionary of next probabble word.\n","3. The second part is that the function iterates over the second dictionary and stores the maximum probabolity number only.\n","4. After we have the max number the function iterates again over this dictionary appending the key to the list choices if their value is equal to the max .\n","5. A list of all the choices is returned and the generation function can choose the next word randomly from all the list of choices.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7797,"status":"ok","timestamp":1618732010009,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"kU7RfJzhRPy9","outputId":"fb93b75a-d94c-4b59-83e8-fbfec646bd18"},"outputs":[{"data":{"text/plain":["['نے']"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["def bigram_predictor(prob_list, word):\n","\n","  max = -1\n","  choices = []\n","  if word in prob_list:\n","    # return prob_list[word]\n","    for i in prob_list[word]:\n","      if prob_list[word][i]> max and i != '</s>' and i != '<s>':\n","        max = prob_list[word][i]\n","    # print(max)\n","\n","    for j in prob_list[word]:\n","      if prob_list[word][j] == max  and j != '</s>' and j != '<s>':\n","        choices.append(j)\n","\n","  \n","  return choices\n","\n","\n","bigram_predictor(probs,\"میں\")\n"]},{"cell_type":"markdown","metadata":{"id":"otnXnZoPz7Vd"},"source":["Poetry generator function using bigrams\n","\n","This function given takes in a list of tokenized list,start words, end words and dictionary of rhymes.\n","\n","Logic:\n","1. Using the tokenized list a 2D dictionary of probabilties is recieved by calling the function Bigram_Probabilities().\n","2. For three stanzas each loop runs 3 times and and then the inner loop runs 4 times for each verse.\n","3. For each verse a random number is generated for its length. The first word is chosen from the list of start words randomly. After thes the next words till (lenght-1) are generated using the Bigram_Predictor function.\n"," RHYMING\n","4. The final word is chosen for a list of end words.The list of end words as explained in the STORING RHYME WORDS section contains words whose pair can be found in the rhyme dictionary.\n","5. Once the rhyme word is chosen for the even verses, in the subsequent odd verse the rhyme word is used as key in the rhyme dictionary which gives a list of possible rhyme word pair. The rhyme word is then chosen randomly.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13910,"status":"ok","timestamp":1618732016126,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"icVC7X-y0BFn","outputId":"3e0db4fa-d047-423b-e4d3-98bf257c095c"},"outputs":[{"name":"stdout","output_type":"stream","text":["   SIMPLE BIGRAM MODEL POETRY  \n","\n","نہ ہو تو نے آخر شب میں غبار \n","ہوائے قرطبہ شاید یہ بات کہ ہیں \n","افکار سے گزر گیا تھا اے نگاہ تو لولاک \n","بندہ ء ناموری ہے، نہ ہو تو نے چالاک \n","\n","کھویا گیا تھا اے نگاہ تو تشنگی \n","اک نفس مرا تذکرہ جو ساقی آئیں \n","زیتون کا یہ بات کہ اس کی طرح عیش تک \n","خرید سکتے ہیں وہ خاک کہ دل اندھیرا \n","\n","نقش و نظر کا یہ بات آباد \n","ندا آئی امتحاں اور بھی ہے یا میرا درد ہے \n","زندگی کا ہر اک دن یہاں فرہاد \n","غلط تھا اے رہرو کہ میں نے نے \n","\n"]}],"source":["def Simple_Bigram_Poetry(total,s_words,e_words,r):\n","\n","\n","  print(\"   SIMPLE BIGRAM MODEL POETRY  \\n\")\n","\n","  # Storing all probabilities using bigram model\n","  verses = []\n","  probabilities = copy.deepcopy(Bigram_Probabilty(total)) # Getting all the probabilities\n","\n","  e_word = \"\"\n","\n","  for i in range(3):\n","\n","    for j in range(4):\n","\n","      temp = []  # List for storing all the words in this verse and will be appended to the list of lists verses\n","\n","      length = random.randint(7,10)  # Length of the line\n","        \n","      #Choosing a start word at random for the start word list that was made when loading the corpus\n","      index =  random.randint(0,len(s_words)-1)\n","      start_word = s_words[index]\n","      \n","      temp.append(start_word)\n","\n","      for k in range(length-2):\n","\n","        options = bigram_predictor(probabilities,start_word) # Gettings the list of options words given the current word\n","        \n","        if(len(options)!= 0):\n","          \n","          if len(options)>1:\n","            c =  random.randint(0,len(options)-1)\n","            # print(options[c],end = \" \")\n","            start_word = options[c]\n","            temp.append(start_word)\n","\n","          elif options[0] != start_word:\n","            # print(options[0])\n","            start_word = options[0]\n","            temp.append(start_word)\n","\n","          else:\n","            ind =  random.randint(0,len(s_words)-1)\n","            start_word = s_words[ind]\n","            temp.append(start_word)\n","\n","        else:\n","          index1 =  random.randint(0,len(s_words)-1)\n","          start_word = s_words[index1]\n","          temp.append(start_word)\n","          # print(start_word,end = \" \")\n","\n","                # R H Y M I N G #\n","      # Choosing last word from list of end words (for even verses)\n","      if j%2 == 0:\n","        index2 =  random.randint(0,len(e_words)-1)\n","        e_word = e_words[index2]\n","        temp.append(e_words[index2])\n","\n","      # Choosing rhyme word for rhyming with previous verse (for odd verses only)  \n","      elif j%2 == 1:\n","        rhyme_choice = r[e_word]\n","        choice_index = random.randint(0,len(rhyme_choice)-1)\n","        temp.append(rhyme_choice[choice_index])\n","      \n","      verses.append(temp)  # Appending the current entire verse to verses\n","\n","\n","  printVerses(verses)\n","  \n","\n","\n","Simple_Bigram_Poetry(total,start_words,end_words,rhymes)\n"]},{"cell_type":"markdown","metadata":{"id":"k5qTAznRY3a2"},"source":["### Backward Bigram Model (with rhyming)"]},{"cell_type":"markdown","metadata":{"id":"9r6CxWLlL7Iz"},"source":["Backward Bigram Model (Without Rhyme Version)\n","\n","Changes compared to the simple bigram model\n","\n","\n","1.   First of all the list of tokenized words is reversed.As a result the bigrams formed,their probabilty disctionanry and the bigram predictor function all do not need to be changed as they will work in the correct way predicting the next word in the same way.Only the word they will be predicting will actually be the previous word.\n","2.   The Second change is that the temp list will be reversed at the end before being appended to the verses(list of list containgi all verses).\n","3.   Third change is that instead of choosing a word from the start words the word will be chosen randomly from a list of end words.\n","4. The end word will be choses fro a list of start word\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7288,"status":"ok","timestamp":1618732025585,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"SkUVig_MTDBW","outputId":"6f156ee1-51ab-450b-db7e-bfd88af04871"},"outputs":[{"name":"stdout","output_type":"stream","text":["   BACKWARD BIGRAM MODEL POETRY  \n","\n","تمہاری سے دل کا بندہ ء رفعت \n","کار ہو جس سے دل میں نہ تھے \n","افکار دل میں نہ ہو چکا ایسے نہیں ناصاف \n","دیکھو مٹنا تجھے کیا ہے جس سے دل میں اچھے \n","\n","یہی کے رہنے والو خدا کے تلے \n","آئے کافوری چاندنی کیا ہے یا شمع \n","ڈھونڈ کی پرواز کیا ہے ، ایسے نہیں باقی \n","دو آج کس خلش پیکاں آسودگئ فتراک \n","\n","ہوں پازند نقش کیا ہے طواف اولیٰ \n","قلب جس سے دل میں نہ سمرقند \n","ملا بہاری یہی کیا ہے اس کی آغوش \n","ادھر صبح ازل کیا ہے کہ بڑھا کون کیا ہے \n","\n"]}],"source":["def Backward_Bigram_Poetry(main_list,s_words,e_words):\n","\n","\n","  print(\"   BACKWARD BIGRAM MODEL POETRY  \\n\")\n","  verses = []\n","\n","  word_list = copy.deepcopy(main_list)\n","  word_list.reverse()\n","\n","  # Storing all probabilities using bigram model\n","  probabilities = copy.deepcopy(Bigram_Probabilty(word_list))\n","\n","\n","  for i in range(3):\n","\n","    for j in range(4):\n","\n","      temp = []\n","\n","      length = random.randint(7,10)  # Length of the line\n","        \n","      #Choosing a start word at random for the start word list that was made when loading the corpus\n","      index =  random.randint(0,len(e_words)-1)\n","      start_word = e_words[index]\n","      \n","      temp.append(start_word)\n","\n","      for k in range(length-2):\n","\n","        options = bigram_predictor(probabilities,start_word)\n","        \n","        if(len(options)!= 0):\n","          \n","          if len(options)>1:\n","            c =  random.randint(0,len(options)-1)         \n","            start_word = options[c]\n","            temp.append(start_word)\n","\n","          elif options[0] != start_word:\n","            # print(options[0])\n","            start_word = options[0]\n","            temp.append(start_word)\n","\n","          else:\n","            ind =  random.randint(0,len(e_words)-1)\n","            start_word = s_words[ind]\n","            temp.append(start_word)\n","\n","        else:\n","          index1 =  random.randint(0,len(e_words)-1)\n","          start_word = e_words[index1]\n","          temp.append(start_word)\n","\n","      # Placing the last words for a list of start words since this is backward model\n","      index2 =  random.randint(0,len(s_words)-1)\n","      temp.append(s_words[index2])\n","\n","      temp.reverse()    # Reversing the list here to coorect the verse produced in reverse fashion\n","      verses.append(temp)\n","  \n","  #Printing the verses produced\n","  printVerses(verses)\n","\n","\n","Backward_Bigram_Poetry(total,start_words,end_words)\n","\n","# back_bigram_verses"]},{"cell_type":"markdown","metadata":{"id":"EentcmTYP15J"},"source":["Backward Bigram Model (Rhyme Version)\n","\n","For Rhyme version the logic is same as the the without rhyme version. The difference is that\n","\n","1. The start word is chosen from the list of end words for even verses.\n","2. For odd verses it is chosen using the the first word of previous verse.\n","\n","(I am using the term first word here since it is the backward bigram model.In reality it is the last word.At the end the verse will be reversed and printed)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13645,"status":"ok","timestamp":1618732031949,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"NnmQJoSAvpV1","outputId":"dbd36f4f-c17d-4462-c0f9-3b73e97cdfc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["   BACKWWARD BIGRAM MODEL POETRY  \n","\n","لب کیا ہے جس سے دل میں آ گیا \n","یک نہ ہو جس سے ھیں کتنے اچھے گیا \n","روز دل بہت کچھ اور بھی ہیں کئی دیپ \n","عروج ناپختہ کیا ہے انبار خس و ہنر مند ھوں \n","\n","مدت خس و مئے ایّام، ورنہ فیض \n","پرندے ہے بے رنگ و عشق و غرب تھے \n","آیا سے دل میں نہ ہو تو کہاں \n","دامن بند پابند کیا ہے یہ دیکھنا مقصود چراغ \n","\n","لاتے ہو تو کہاں کیا ہے رقیب \n","ایمان ہے انبار خس و نظر ہوگا \n","جب جس سے دل میں نہ ہو جس سے نومیدی \n","غریب مجھ کو خدا کے آزاد ہے! \n","\n"]}],"source":["def R_Backward_Bigram_Poetry(main_list,s_words,e_words,r):\n","\n","  print(\"   BACKWWARD BIGRAM MODEL POETRY  \\n\")\n","\n","  verses = []\n","\n","  word_list = copy.deepcopy(main_list)\n","  word_list.reverse()\n","\n","  # Storing all probabilities using bigram model\n","  probabilities = copy.deepcopy(Bigram_Probabilty(word_list))\n","\n","\n","  for i in range(3):\n","\n","    prev_word = \"\"\n","\n","    for j in range(4):\n","   \n","      temp = []\n","\n","      length = random.randint(7,10)  # Length of the line\n","             \n","      start_word = \"\"\n","\n","                      # R H Y M I N G #\n","      # Choosing last word from list of first words (for even verses)\n","      if j%2 == 0:\n","        index =  random.randint(0,len(e_words)-1)\n","        start_word = e_words[index]\n","        temp.append(start_word)\n","        prev_word = copy.deepcopy(start_word)\n","\n","      # Choosing rhyme word for rhyming with previous verse (for odd verses only)  \n","      elif j%2 == 1:\n","        rhyme_choice = r[prev_word]\n","        choice_index = random.randint(0,len(rhyme_choice)-1)\n","        temp.append(rhyme_choice[choice_index])\n","\n","\n","      for k in range(length-2):\n","\n","        options = bigram_predictor(probabilities,start_word)\n","        \n","        if(len(options)!= 0):\n","          \n","          if len(options)>1:\n","            c =  random.randint(0,len(options)-1)         \n","            start_word = options[c]\n","            temp.append(start_word)\n","\n","          elif options[0] != start_word:\n","            # print(options[0])\n","            start_word = options[0]\n","            temp.append(start_word)\n","\n","          else:\n","            ind =  random.randint(0,len(s_words)-1)\n","            start_word = s_words[ind]\n","            temp.append(start_word)\n","\n","        else:\n","          index1 =  random.randint(0,len(e_words)-1)\n","          start_word = e_words[index1]\n","          temp.append(start_word)\n","\n","      # Placing the last words for a list of start words since this is backward model\n","      index2 =  random.randint(0,len(s_words)-1)\n","      temp.append(s_words[index2])\n","\n","      temp.reverse()    # Reversing the list here to coorect the verse produced in reverse fashion\n","\n","      verses.append(temp)\n","  \n","  #Printing the verses produced\n","  printVerses(verses)\n","\n","\n","R_back_bigram_verses = R_Backward_Bigram_Poetry(total,start_words,end_words,rhymes)\n"]},{"cell_type":"markdown","metadata":{"id":"i2LlJjcAbxdA"},"source":["### Bidirectional Bigram Model (with rhyming)"]},{"cell_type":"markdown","metadata":{"id":"dm53DZ24b5Yu"},"source":["For this model the logic on which it will work is that the generated verse length will be divided into half. \n","1. The first half will be generated using the the bigram probabilties of simple bigrams.\n","2. The second half will be generated using backward bigram probabilities.\n","3. Rhyming will be done in the backward bigram part such that the last word will be chosen from the dictionary of rhymes."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13825,"status":"ok","timestamp":1618732046918,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"8Yqfjzgbb54z","outputId":"1f759d80-4daf-4faa-b1ce-c15610b1342c"},"outputs":[{"name":"stdout","output_type":"stream","text":["   BIDIRECTIONAL BIGRAM MODEL POETRY  \n","\n","نفس مرا شعلہ بار بنیاد ہے اس کی بہار \n","بندہ بنوں گا سارا نظر دل و زندیق گزر \n","حاضر ہے یا میرا شعیہ ٹھکانہ ابھی وہی طہٰ \n","گو اس کی طرح بغداد ہے یہ توفیق ورنہ \n","\n","ستم کش انتظار ہوگا افلاک ہو تو نہیں ھیں \n","مگر یہ بات خلاف نہ سمرقند اشارے \n","بندہ بنوں گا جس جائیو میں نہ ہو طلب \n","سبق شاہیں بناتا نہیں ہے دریا پھر کسے خبر کرو آرہوں \n","\n","آؤ نہ ہو تو ہو ہو تو خود را \n","لوگوں کو بھی ہے یا کتنی بھی ہیں روز حساب نے \n","جگنو کی طرح عیش سبق گزر ایسے نہیں بدلی \n","لو وصل کی طرح پیہم و مستی گفتار کا \n","\n"]}],"source":["def Bidirectional_Bigram_Poetry(forward_list,s_words,e_words,r):\n","\n","  print(\"   BIDIRECTIONAL BIGRAM MODEL POETRY  \\n\")\n","\n","  verses = []\n","\n","  backward_list = copy.deepcopy(forward_list)\n","  backward_list.reverse() # A reversed list for backward bigram model\n","\n","  # 2D dictionanry to hold all forward bigram probs\n","  prob_forward = copy.deepcopy(Bigram_Probabilty(forward_list))\n","\n","  # 2D dictionanry to hold all backward bigram probs\n","  prob_back = copy.deepcopy(Bigram_Probabilty(backward_list))\n","\n","  #STANZA\n","  for i in range(3):  \n","\n","    prev_word = \"\"\n","\n","    #VERSE\n","    for j in range(4): \n","   \n","      temp1 = []\n","      temp = []\n","\n","      length = random.randint(7,10)  # Length of the line\n","             \n","      start_word = \"\"\n","\n","      ################# SIMPLE BIGRAM PART  ####################\n","\n","      #Choosing a start word at random for the start word list that was made when loading the corpus\n","      index =  random.randint(0,len(s_words)-1)\n","      start_word = s_words[index]\n","      \n","      temp1.append(start_word)\n","\n","      for k in range(int((length-2)/2)):\n","\n","        options1 = bigram_predictor(prob_forward,start_word) # Gettings the list of options words given the current word\n","        \n","        if(len(options1)!= 0):\n","          \n","          if len(options1)>1:\n","            c =  random.randint(0,len(options1)-1)\n","            # print(options1[c],end = \" \")\n","            start_word = options1[c]\n","            temp1.append(start_word)\n","\n","          elif options1[0] != start_word:\n","            # print(options1[0])\n","            start_word = options1[0]\n","            temp1.append(start_word)\n","\n","          else:\n","            ind =  random.randint(0,len(s_words)-1)\n","            start_word = s_words[ind]\n","            temp1.append(start_word)\n","\n","        else:\n","          index1 =  random.randint(0,len(s_words)-1)\n","          start_word = s_words[index1]\n","          temp1.append(start_word)\n","          # print(start_word,end = \" \")\n","\n","      # print(\"Forward-> \",temp1)\n","      \n","\n","      ################# BACKWARD BIGRAM PART  ####################\n","      start_word = \"\"\n","\n","                      # R H Y M I N G #\n","      # Choosing last word from list of first words (for even verses)\n","      if j%2 == 0:\n","        index =  random.randint(0,len(e_words)-1)\n","        start_word = e_words[index]\n","        temp.append(start_word)\n","        prev_word = copy.deepcopy(start_word)\n","\n","      # Choosing rhyme word for rhyming with previous verse (for odd verses only)  \n","      elif j%2 == 1:\n","        rhyme_choice = r[prev_word]\n","        choice_index = random.randint(0,len(rhyme_choice)-1)\n","        temp.append(rhyme_choice[choice_index])\n","\n","\n","      for k in range(int((length-2)/2)):\n","\n","        options = bigram_predictor(prob_back,start_word)\n","        \n","        if(len(options)!= 0):\n","          \n","          if len(options)>1:\n","            c =  random.randint(0,len(options)-1)         \n","            start_word = options[c]\n","            temp.append(start_word)\n","\n","          elif options[0] != start_word:\n","            # print(options[0])\n","            start_word = options[0]\n","            temp.append(start_word)\n","\n","          else:\n","            ind =  random.randint(0,len(s_words)-1)\n","            start_word = s_words[ind]\n","            temp.append(start_word)\n","\n","        else:\n","          index1 =  random.randint(0,len(e_words)-1)\n","          start_word = e_words[index1]\n","          temp.append(start_word)\n","\n","      # Placing the last words for a list of start words since this is backward model\n","      index2 =  random.randint(0,len(e_words)-1)\n","      temp.append(e_words[index2])\n","\n","      temp.reverse()    # Reversing the list here to coorect the verse produced in reverse fashion\n","      # print(\"Backward-> \",temp)\n","\n","      verse = temp1 + temp\n","      verses.append(verse)  # Appending the current entire verse to verses\n","\n","  printVerses(verses)\n","\n","\n","\n","\n","Bidirectional_Bigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"roX2ncfeuFlz"},"source":["### Trigram Model (with rhyming)"]},{"cell_type":"markdown","metadata":{"id":"Tmp5U4YLcaaB"},"source":["Trigram Probability calculation function\n","\n","This function is similar in logic to the bigram probabilty function however the key of the key of the first dictionary in the 2D dictionary is a tuple of two words rather then just being a single word.\n","\n","EXAMPLE:\n","\n","('کبھی', 'تو'): {'شب': 0.5, 'صبح': 0.5'}\n","\n","1. Here ('کبھی', 'تو') is the key of the first dictionary.\n","2. 'صبح' and 'شب' are keys in the second dictionary.\n","3. The probabilty of 'شب' occuring after ('کبھی', 'تو') is 0.5."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13136,"status":"ok","timestamp":1618732062247,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"6ZK7Z3KouKE2","outputId":"c66069d3-2927-4638-ea24-f620afdb4b03"},"outputs":[],"source":["def Trigram_Probabilty(total):\n","\n","  mainDict = defaultdict(list)  # This dictionary holds a list of dictionaries\n","\n","  back2 = \"\"\n","  back1 = \"\"\n","  for i in range(len(total)):\n","    if i > 0:\n","      if back1 != \"\" and back2 != \"\":\n","        mainDict[(back2,back1)].append(total[i])\n","      back1 = total[i]\n","      back2 = total[i-1]\n","\n","  for key in mainDict.keys():\n","\n","    count = countDouble(key[0],key[1],total)\n","    # print(key,\"->\",count)\n","    next_words = mainDict[key]  # Getting the whole list of words after the key word\n","    unique_words = set(next_words)  # Remaove duplicates\n","    probabilities_key = {}\n","\n","     # Now we will iterate over the list of words after the key word,and store probabilty with each word\n","    for u in unique_words:\n","      # print(key,\" \",u,\"->\",countDouble(key,u,total))\n","      count2 = countTriple(key[0],key[1],u,total)\n","      probabilities_key[u] = copy.deepcopy(count2/count)\n","\n","    mainDict[key] = probabilities_key\n","\n","  return mainDict\n","\n","\n","tri_prob = Trigram_Probabilty(total)\n","tri_prob\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NEr_eCyp6eyR"},"source":["Trigram Predictor Function\n","\n","1. The logic is again similar to the bigram predictor function.\n","\n","2. The Difference is that the function recieves two words instead of one since this is a trigram model and two words are needed to access the key of the first dictioanry.\n","\n","3. Finally it returns a list of choices given the previous two words and the next word is chosen randomly for the choices by the generation function"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13132,"status":"ok","timestamp":1618732062249,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"WzOeyK7i6hcA","outputId":"01f6a193-0690-4875-948f-38b0074e33fc"},"outputs":[{"data":{"text/plain":["['دوبارا', 'چمکا', 'چلا']"]},"execution_count":16,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["def trigram_predictor(prob_list, word1,word2):\n","\n","  max = -1\n","  choices = []\n","  if (word1,word2) in prob_list:\n","    # return prob_list[word]\n","    for i in prob_list[(word1,word2)]:\n","      if prob_list[(word1,word2)][i]> max and i != '</s>' and i != '<s>':\n","        max = prob_list[(word1,word2)][i]\n","    # print(max)\n","\n","    for j in prob_list[(word1,word2)]:\n","      if prob_list[(word1,word2)][j] == max  and j != '</s>' and j != '<s>':\n","        choices.append(j)\n","\n","  \n","  return choices\n","\n","\n","trigram_predictor(tri_prob,'آ', 'کے')"]},{"cell_type":"markdown","metadata":{"id":"0hHr9Vlg89d6"},"source":["Trigram poetry generator\n","\n","Logic:\n","\n","1. The first word is choses randomly from the list of start words,similar to the bigram model.\n","2. This function also calculates tht bigram probabilites and using the bigram predictor function the second word of each verse is printed using the bigram predictor function for accuracy  and so that the second word is not disjointed in meaning or style.\n","3. After having generated the first two words the remaing words of the verses are generated using the trigram predictor function.\n","RHYMING\n","4. The final word is is chosen from a list of end words for even verses.\n","5. For odd verses the rhyme option is chosen randomly given the end word of the previous verse as the key. "]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31809,"status":"ok","timestamp":1618732080931,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"GUfJM4bM8__x","outputId":"dac82bef-80c2-43b3-95ce-8c05739b6b39"},"outputs":[{"name":"stdout","output_type":"stream","text":["   TRIGRAM MODEL POETRY  \n","\n","سنا ہے یہ قدسیوں سے میں نے وہ شیر میری \n","چاند سے ماند ستاروں نے کہا آخر شب ہے! \n","بُھولے تو یوں کہ جیسے ہمیشہ آئے \n","افلاک پر بھول جدا ایک بہت میرے لبریز آئے \n","\n","خدا کے بندوں سے پیار ہوگا لطیفۂ ناداں خوف مہرباں \n","دیکھو تو کدھر آج رخ باد صبا آخر تھے \n","پہنچوں کس طرح غوروفکر سے بےنام قوم الا \n","لمس جانانہ لیے مستیٔ پیمانہ لیے کریں بغل نے \n","\n","سونپا تھا جسے کام نگہبانئ دل کا خاشاک \n","علم چارہ گر کو چارہ گری سے آنسو \n","میں نے وہ شیر پھر ہوشیار منزل \n","چپ رہ نہ سکا قند اگر فقط علاج ندا آئے \n","\n"]}],"source":["def Trigram_Poetry(t_words,s_words,e_words,r):\n","\n","  print(\"   TRIGRAM MODEL POETRY  \\n\")\n","\n","  verses = []\n","\n","   # Getting all the probabilities for trigram\n","  trigram_probs = copy.deepcopy(Trigram_Probabilty(t_words))\n","\n","  # Getting all probabilties from bigram model to predict the second word in each verse\n","  bigram_probs = copy.deepcopy(Bigram_Probabilty(t_words))  \n","\n","  e_word = \"\"\n","\n","  for i in range(3):\n","\n","    for j in range(4):\n","\n","      temp = []  # List for storing all the words in this verse and will be appended to the list of lists verses\n","\n","      start_word = \"\"\n","      start_word2 = \"\"\n","\n","      length = random.randint(7,10)  # Length of the line\n","        \n","      #Choosing a start word at random for the start word list that was made when loading the corpus\n","      index =  random.randint(0,len(s_words)-1)\n","      start_word = s_words[index]\n","      \n","      temp.append(start_word)\n","\n","      # Predicting second word using bigram probabilties for more accuracy\n","      ##################################\n","      b_options = bigram_predictor(bigram_probs,start_word)\n","      if(len(b_options)!= 0):\n","          \n","        if len(b_options)>1:\n","          c =  random.randint(0,len(b_options)-1)\n","          # print(options[c],end = \" \")\n","          start_word2 = b_options[c]\n","          temp.append(start_word2)\n","\n","        elif len(b_options) == 1 and b_options[0] != start_word:\n","          # print(options[0])\n","          start_word2 = b_options[0]\n","          temp.append(start_word2)\n","\n","        else:\n","          ind =  random.randint(0,len(s_words)-1)\n","          start_word2 = s_words[ind]\n","          temp.append(start_word2)\n","\n","      else:\n","        index1 =  random.randint(0,len(s_words)-1)\n","        start_word2 = s_words[index1]\n","        temp.append(start_word2)\n","\n","\n","      ############################################\n","\n","\n","      # USING START_WORD AND START_WORD2 FOR TRIGRAM CALCULATIONS\n","\n","      # ******* #\n","      for k in range(length-3):\n","\n","        start_word3 = \"\"\n","        options = trigram_predictor(trigram_probs,start_word,start_word2) # Gettings the list of options words given the current word\n","        \n","        if(len(options)!= 0):\n","          \n","          if len(options)>1:\n","            c =  random.randint(0,len(options)-1)\n","            # print(options[c],end = \" \")\n","            start_word3 = options[c]\n","            temp.append(start_word3)\n","\n","          elif len(options) == 1 and options[0] != start_word2:\n","            # print(options[0])\n","            start_word3 = options[0]\n","            temp.append(start_word3)\n","\n","          else:\n","            ind =  random.randint(0,len(s_words)-1)\n","            start_word3 = s_words[ind]\n","            temp.append(start_word3)\n","\n","        else:\n","          index1 =  random.randint(0,len(s_words)-1)\n","          start_word3 = s_words[index1]\n","          temp.append(start_word3)\n","\n","        start_word = copy.deepcopy(start_word2)\n","        start_word2 = copy.deepcopy(start_word3)\n","          \n","\n","                # R H Y M I N G #\n","      # Choosing last word from list of end words (for even verses)\n","      if j%2 == 0:\n","        index2 =  random.randint(0,len(e_words)-1)\n","        e_word = e_words[index2]\n","        temp.append(e_words[index2])\n","\n","      # Choosing rhyme word for rhyming with previous verse (for odd verses only)  \n","      elif j%2 == 1:\n","        rhyme_choice = r[e_word]\n","        choice_index = random.randint(0,len(rhyme_choice)-1)\n","        temp.append(rhyme_choice[choice_index])\n","      \n","      verses.append(temp)  # Appending the current entire verse to verses\n","\n","\n","  printVerses(verses)\n","  \n","\n","Trigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"RYMHZ20bV9r1"},"source":["### Comparisons Between Models"]},{"cell_type":"markdown","metadata":{"id":"aar6yBeD_Zi0"},"source":["UNIGRAM MODEL\n","\n","Analysis:\n","As it can be seen the unigram model even with the logic of choosing one connecting word and one high value word does not make much sense compred to the other model. Every two words in each verse are disjointed and do not feel right synctactically."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1944,"status":"ok","timestamp":1618732085176,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"0SblY35uWDf-","outputId":"3f377976-dea0-4d33-8a92-c82f4c3cc2bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["     UNIGRAM MODEL POETRY\n","\n","بے قلندری طریقت بندے لمس سخن گوارا خواروں ید آیا \n","بندگی وجدان بھروسا دھمکانے اڑا گھڑی محشر پر \n","دماغ پرویز قرطبہ حکم کاروبار اچھے زنجیر شے \n","کتابِ لاکھ مغربیاں شکوے برپا دیکھو فرہاد پرویز دماغ \n","\n","وہ ذکر مثل خاشاک کافری گستاخ ناصاف شعیہ \n","ترے آنکھوں جنگاہ جا کاربندِ یارو شاہین سکندری واسطہ \n","رکھتی افق طریقت فلک شدہ شیشہ بتاں ، پسند جسے \n","گنو شاعر دہناں تمدن ٹوٹا حکم قلم چگنے دیا \n","\n","بدلتا فرزندی جوئے جاتی سولی فاش آئے \n","بڑی آزما اندیش انداز اٹھتی حجاب آئے \n","سلوک والو اویس جب عجیب گزار چلو ہجراں \n","کسی بتاؤں گلے  خلیق دور چلے \n","\n"]}],"source":["Unigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"S8Km80aA_7vC"},"source":["SIMPLE BIGRAM MODEL\n","\n","Analysis:\n","The backward bigram model is a huge improvement over the unigram model. The verses for the most part fulfill the synctactic criteria but meaning wise they feel a little disjointed after every 2-3 words in each verse. The rhyming as it can be seen fits well but it does not always join smoothly with the words behinf it. This is bacause the last word is chosen as soon as the loop lenght of the verse runs out. It is not chosen using the bigram prediction."]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7322,"status":"ok","timestamp":1618732104896,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"0d5oQz2y_8Er","outputId":"6344a13b-71ed-4d07-cd69-3e1fa39bbda2"},"outputs":[{"name":"stdout","output_type":"stream","text":["   SIMPLE BIGRAM MODEL POETRY  \n","\n","حمد باری کو بھی ہے یا سنائیو \n","تری زیبائی سے گزر گیا ہے یا کریں \n","افکار کی طرح عیش نیام سے گزر گیا تھا کی \n","زمانے ميں تفاوت نہيں ليکن ذرا سا چھپا تھے \n","\n","صنم آشنا تجھے مثال شرار ہوگا نو نومبر چاھے \n","اس کی طرح عیش نیام سے گزر گیا تھا ھے \n","بھروسا کر کوئی بات کہ دل اترے \n","جہان مے خانہ سن کے دیکھ لیا ھو آئے \n","\n","ہزار کر کے دیکھ لیا جسے حق نے سخن آغوش \n","اندیشۂ چالاک طرب آشنائے خروش ہو تو نے کیا نہیں \n","رہے ہیں وہ خاک کہ میں نے بادہ خوار استغنا \n","ہنسی آتی ہے یا میرا دل کا کی \n","\n"]}],"source":["Simple_Bigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"g9dNgM7j_8gy"},"source":["BACKWARD BIGRAM MODEL\n","\n","Analysis:\n","The Backward Bigram model is similar to the simple bigram model in this regard.The last word feels better here since the words generated before it are predicted using the bigram predictor function. However now the problem occurs slightly as the forst word feels a little disjointed since it is chosen after the loop to end the verse. Syntax wise the verses are correct for the most part however meaning wise it is still poor."]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7690,"status":"ok","timestamp":1618732128297,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"rn_YnBdd_9Hy","outputId":"cb06ff1a-05e3-4404-8104-1cc383288d12"},"outputs":[{"name":"stdout","output_type":"stream","text":["   BACKWWARD BIGRAM MODEL POETRY  \n","\n","مہ دل میں کچھ اور بھی ہیں زیاد \n","وضع مجھ کو بخشی سختی خارا حجاب \n","عروج ہو تو جاں کیا غم فرہاد \n","کون سے دل میں نہ سمجھو نے \n","\n","دبا سے گزر کیا ہے یہ کہکشاں برگیبانِ مرغزار \n","جدا دل کا سفر نظارۂ بام سحاب \n","بنگر باغ بہشت مغربیاں جلوہ ہائے پا برکاب \n","متاع دل میں نہ ہو تو جاں عدو جا \n","\n","نئی دل میں نہ ہو تو پھر کسے خبر کرو \n","نگہ نہ ہو تو تھیں قربتیں کتنی دیا \n","بنااُڑے مجھ کو خدا کے رہنے والو خدا کے لانا \n","ترے جس سے دل میں نہ سمجھو یارو \n","\n"]}],"source":["R_Backward_Bigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"4qMx73pj_9oD"},"source":["BIDIRECTIONAL BIGRAM MODEL\n","\n","Analysis:The bigram model is the best of both simple bigram and backward bigram model since there is no disjoint meaning at the start and end of most of the verses as seen below. However the logic used is that half of the verse is generated from the back and half from the front. As a result sometimes the verse is slightly dijointed at the middle of the verse.\n","Meaning wise the model is similar to backward bigram and simple bigram model. "]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13478,"status":"ok","timestamp":1618732154162,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"TpA1KNCt_-Dz","outputId":"f0f555da-283e-44b8-ed86-47e8afd4d4dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["   BIDIRECTIONAL BIGRAM MODEL POETRY  \n","\n","حمد باری کو میری تھیں قربتیں کتنی \n","سچ ہے یا میرا دیا میں اس کی کیا \n","تر دامنی پہ یارو پرویز میں نہ ہو تو \n","چیتے کا ہر اک صیاد باقی ھو تشنگی تھا \n","\n","عقل کو نہ ہو سمجھا جس سے دل غریب \n","مقامات آہ و نظر لاتخف خدا کے در اپنا \n","چاند کے دیکھ دریا زمانے بھول گئے \n","لرزیدہ میری نفس پر خبر کرو تھا \n","\n","سنائے کون غزل خواں ہے پروا میں نہ کر کوئی ہدف \n","مے خانہ ہر اک نفس اعراف نہ کر کوئی ستارہ نہیں \n","قافلہِ عشق و نظر پازند جو شاخ یقیں نمناک \n","رہ جا تو نے ہمیں اعراف ہے جس سے خموش بیباکی \n","\n"]}],"source":["Bidirectional_Bigram_Poetry(total,start_words,end_words,rhymes)"]},{"cell_type":"markdown","metadata":{"id":"jA7EgE5cIHn7"},"source":["TRIGRAM MODEL\n","\n","Analysis: The trigram model is by far the best of all the model as seen from the poetry generated below. Syntax wise there is almost no errors or disjoint parts. This model is even superior meaning wise as some verses actually qualify for poetry to some extent. The model chooses the forst word at random but the second word is chosen using bigram and the subsequents words using trigrams. As a relsult the syntax is so smooth that even the last word which is chosen wothout any context seems to fit in most verses."]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20706,"status":"ok","timestamp":1618733135243,"user":{"displayName":"Omer Anwar","photoUrl":"","userId":"02895344091745001426"},"user_tz":-300},"id":"3FgAQ8eFIH9j","outputId":"01f2470e-3a32-4c83-82c5-07a61eb6a44e"},"outputs":[{"name":"stdout","output_type":"stream","text":["   TRIGRAM MODEL POETRY  \n","\n","دامن نچوڑ دیں تو فکر دل و نظر کا گئے \n","کتابِ خودی کا انوکھا کردار ہے تھا \n","کبھی تو صبح ترے کنج لب سے ہو بیتابی \n","شمع نے یہ کہا کہ وہ اثر کہن اگرچہ آیا \n","\n","تم سمجھ رہے ہو وہ اب زر یعنی \n","اسے اب چاند کے غاروں میں نظر بند پایا \n","گلیوں میں پھرا کرتے تھے دو چار دوانے جہان گداز \n","نام پہ خالی سبو کریں پرسوز ڈھونڈھنا \n","\n","تھک کر یوں ہی پل بھر نزول \n","تاویل سے قرآں کو بنا سکتے ہیں کھلا \n","قناعت نہ کر تلف چمکا صوفی ضبط سینے 'کیا'؟ \n","قصوروار غریب الدیار ہوں لیکن نکل راہ \n","\n"]}],"source":["Trigram_Poetry(total,start_words,end_words,rhymes)"]}],"metadata":{"colab":{"collapsed_sections":["6ZWnhEjj9-Aa","BYujvfHy580G","FOoXq--POObz","k5qTAznRY3a2","i2LlJjcAbxdA","roX2ncfeuFlz"],"name":"i18-0562.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
